{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40c7467-64bc-464c-81e5-4db2863648b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from train_utils import Evaluator, Trainer, train, train_certified_wm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utils2 import DataUtils, generate_adv_trigger, generate_random_trigger\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c816a0e7-153d-4c0d-bc67-15229a5079e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10/cifar-10-python.tar.gz to ./data/CIFAR10\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10/test: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 20669.71it/s]\n",
      "./data/CIFAR10/clean/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 18187.64it/s]\n",
      "./data/CIFAR10/with_trigger/val: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9980/9980 [00:00<00:00, 20037.39it/s]\n",
      "./data/CIFAR10/with_trigger/train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 35928/35928 [00:01<00:00, 20049.45it/s]\n",
      "./data/CIFAR10/with_trigger/train_incre: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3992/3992 [00:00<00:00, 20129.55it/s]\n",
      "./data/CIFAR10/with_trigger/trigger_clean: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 19182.73it/s]\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='cifar10',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.1, cache_path='../Watermarking/data/cifar-10-python.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f942aa81-7fef-4ba5-baa3-3d876548965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10_8020/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10_8020/cifar-10-python.tar.gz to ./data/CIFAR10_8020\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10_8020/test: 100%|████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 19313.42it/s]\n",
      "./data/CIFAR10_8020/clean/train: 100%|█████████████████████████████████████████| 50000/50000 [00:02<00:00, 19043.53it/s]\n",
      "./data/CIFAR10_8020/with_trigger/val: 100%|██████████████████████████████████████| 2495/2495 [00:00<00:00, 16936.71it/s]\n",
      "./data/CIFAR10_8020/with_trigger/train: 100%|██████████████████████████████████| 37924/37924 [00:02<00:00, 18665.13it/s]\n",
      "./data/CIFAR10_8020/with_trigger/train_incre: 100%|██████████████████████████████| 9481/9481 [00:00<00:00, 18809.42it/s]\n",
      "./data/CIFAR10_8020/with_trigger/trigger_clean: 100%|██████████████████████████████| 100/100 [00:00<00:00, 18779.91it/s]\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='cifar10_8020',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=0.95,\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.2, cache_path='../Watermarking/data/cifar-10-python.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c68c43-710f-4de2-8451-5afc4c80b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10_7030/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10_7030/cifar-10-python.tar.gz to ./data/CIFAR10_7030\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10_7030/test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 20337.29it/s]\n",
      "./data/CIFAR10_7030/clean/train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 20113.87it/s]\n",
      "./data/CIFAR10_7030/with_trigger/val: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2495/2495 [00:00<00:00, 16044.21it/s]\n",
      "./data/CIFAR10_7030/with_trigger/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33183/33183 [00:01<00:00, 19897.94it/s]\n",
      "./data/CIFAR10_7030/with_trigger/train_incre: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14222/14222 [00:00<00:00, 19707.04it/s]\n",
      "./data/CIFAR10_7030/with_trigger/trigger_clean: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 18692.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='cifar10_7030',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=0.95,\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.3, cache_path='../Watermarking/data/cifar-10-python.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b70cfde6-1fc5-41fd-b5fa-d09f8101c651",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Dataset name is invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_utils \u001b[38;5;241m=\u001b[39m \u001b[43mDataUtils\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcifar10_7525\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrigger_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m data_utils\u001b[38;5;241m.\u001b[39msave_image(incre_train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, cache_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Watermarking/data/cifar-10-python.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/hdd/projects/CS_FYP/data_utils.py:40\u001b[0m, in \u001b[0;36mDataUtils.__init__\u001b[0;34m(self, dataset_name, root_dir, train_ratio, trigger_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR10_7030\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset name is invalid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ratio \u001b[38;5;241m=\u001b[39m train_ratio\n",
      "\u001b[0;31mException\u001b[0m: Dataset name is invalid"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='cifar10_7525',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=0.95,\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.25, cache_path='../Watermarking/data/cifar-10-python.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b31165-463a-477d-90df-e5644a54cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_random_trigger('./data/CIFAR10')\n",
    "# generate_random_trigger('./data/CIFAR10_8020')\n",
    "generate_random_trigger('./data/CIFAR10_7030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da0eb27-a8ca-42e7-a749-a149579843f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a5a2acc-7e8d-4044-9727-7adfe87c086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18().cuda()\n",
    "    y = net(torch.randn(1, 3, 32, 32).cuda())\n",
    "    print(y.size())\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f817ff1b-f2c2-41e3-96f1-6050faf838eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet import ResNet18\n",
    "# net = ResNet18()\n",
    "# net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "# generate_adv_trigger(net, './data/CIFAR10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640a04f7-29c5-465b-afe6-cf8db83fe113",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarkset = datasets.ImageFolder('./data/CIFAR10/with_trigger/trigger_random/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbaeb99-3886-4a7c-8aca-a664594e54c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean set: 74.0\n",
      "Accuracy on adv set: 21.0\n"
     ]
    }
   ],
   "source": [
    "from resnet import ResNet18\n",
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "# generate_adv_trigger(net, './data/CIFAR10/')\n",
    "generate_adv_trigger(net, './data/CIFAR10_7030/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984e157-ae89-4193-9f86-3faf9412ba82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "781bcbc5-c7eb-4d5c-ad90-1b5f5164fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10/cifar-10-python.tar.gz to ./data/CIFAR10\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10/test: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 20398.69it/s]\n",
      "./data/CIFAR10/clean/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 19620.41it/s]\n",
      "./data/CIFAR10/with_trigger/train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44910/44910 [00:02<00:00, 19988.12it/s]\n",
      "./data/CIFAR10/with_trigger/train_incre: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4990/4990 [00:00<00:00, 20102.02it/s]\n",
      "./data/CIFAR10/with_trigger/trigger_clean: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 19634.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean set: 74.0\n",
      "Accuracy on adv set: 21.0\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='cifar10',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=1\n",
    "    \n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.1, cache_path='../Watermarking/data/cifar-10-python.tar.gz')\n",
    "generate_random_trigger('./data/CIFAR10')\n",
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "generate_adv_trigger(net, './data/CIFAR10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b35086e7-5c67-4e0c-929f-724cfe3d20a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10_8020/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10_8020/cifar-10-python.tar.gz to ./data/CIFAR10_8020\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10_8020/test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 20244.27it/s]\n",
      "./data/CIFAR10_8020/clean/train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 20146.55it/s]\n",
      "./data/CIFAR10_8020/with_trigger/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39920/39920 [00:02<00:00, 19701.98it/s]\n",
      "./data/CIFAR10_8020/with_trigger/train_incre: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9980/9980 [00:00<00:00, 19906.67it/s]\n",
      "./data/CIFAR10_8020/with_trigger/trigger_clean: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 18123.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean set: 74.0\n",
      "Accuracy on adv set: 21.0\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='CIFAR10_8020',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=1\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.20, cache_path='../Watermarking/data/cifar-10-python.tar.gz')\n",
    "generate_random_trigger('./data/CIFAR10_8020')\n",
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "generate_adv_trigger(net, './data/CIFAR10_8020/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9a10ec-1c53-4d2f-b9e3-8835e168d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10_7030/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10_7030/cifar-10-python.tar.gz to ./data/CIFAR10_7030\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10_7030/test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 20352.78it/s]\n",
      "./data/CIFAR10_7030/clean/train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 19398.14it/s]\n",
      "./data/CIFAR10_7030/with_trigger/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34930/34930 [00:01<00:00, 19844.67it/s]\n",
      "./data/CIFAR10_7030/with_trigger/train_incre: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14970/14970 [00:00<00:00, 19905.69it/s]\n",
      "./data/CIFAR10_7030/with_trigger/trigger_clean: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 19305.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean set: 74.0\n",
      "Accuracy on adv set: 21.0\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='CIFAR10_7030',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=1\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.3, cache_path='../Watermarking/data/cifar-10-python.tar.gz')\n",
    "generate_random_trigger('./data/CIFAR10_7030')\n",
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "generate_adv_trigger(net, './data/CIFAR10_7030/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e890df71-f9ee-4a3e-8d9f-e85f6f710452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10_6040/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10_6040/cifar-10-python.tar.gz to ./data/CIFAR10_6040\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10_6040/test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 19985.31it/s]\n",
      "./data/CIFAR10_6040/clean/train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 20330.45it/s]\n",
      "./data/CIFAR10_6040/with_trigger/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29940/29940 [00:01<00:00, 19609.93it/s]\n",
      "./data/CIFAR10_6040/with_trigger/train_incre: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19960/19960 [00:01<00:00, 19366.79it/s]\n",
      "./data/CIFAR10_6040/with_trigger/trigger_clean: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 5905.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean set: 74.0\n",
      "Accuracy on adv set: 21.0\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='CIFAR10_6040',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=1\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.4, cache_path='../Watermarking/data/cifar-10-python.tar.gz')\n",
    "generate_random_trigger('./data/CIFAR10_6040')\n",
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "generate_adv_trigger(net, './data/CIFAR10_6040/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cdbe30a-d4ce-4512-90c6-f4c655d27ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/CIFAR10_5050/cifar-10-python.tar.gz\n",
      "Extracting ./data/CIFAR10_5050/cifar-10-python.tar.gz to ./data/CIFAR10_5050\n",
      "Files already downloaded and verified\n",
      "Save data to:\n",
      "===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./data/CIFAR10_5050/test: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 20419.44it/s]\n",
      "./data/CIFAR10_5050/clean/train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:02<00:00, 20069.15it/s]\n",
      "./data/CIFAR10_5050/with_trigger/train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24950/24950 [00:01<00:00, 17480.24it/s]\n",
      "./data/CIFAR10_5050/with_trigger/train_incre: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24950/24950 [00:01<00:00, 18143.85it/s]\n",
      "./data/CIFAR10_5050/with_trigger/trigger_clean: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 802.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean set: 74.0\n",
      "Accuracy on adv set: 21.0\n"
     ]
    }
   ],
   "source": [
    "data_utils = DataUtils(\n",
    "    dataset_name='CIFAR10_5050',\n",
    "    root_dir='./data',\n",
    "    trigger_size=100,\n",
    "    train_ratio=1\n",
    ")\n",
    "data_utils.save_image(incre_train_size=0.5, cache_path='../Watermarking/data/cifar-10-python.tar.gz')\n",
    "generate_random_trigger('./data/CIFAR10_5050')\n",
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('../Watermarking/checkpoint/Tu/resnet18_exp2.ckpt'))\n",
    "generate_adv_trigger(net, './data/CIFAR10_5050/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7078f9-ec96-4cac-ab2f-1bb9d9f60fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b31d7-a096-4a15-a362-5e2a2d97d719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
